{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-EBVlqef4HA"
      },
      "outputs": [],
      "source": [
        "# Gavin Casper and Kai Hiratani"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression,LinearRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "import argparse\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "from xgboost import XGBClassifier"
      ],
      "metadata": {
        "id": "uhg5ijTwQSmL"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "file_path_Gavin = '/content/drive/MyDrive/hotel_booking.csv'\n",
        "# replace this with where your csv file is located in google drive, I tested if it worked with different accounts\n",
        "file_path_Kai = '/content/drive/MyDrive/hotel_booking.csv'\n",
        "\n",
        "# Load the CSV into a DataFrame\n",
        "data = pd.read_csv(file_path_Gavin)\n",
        "\n",
        "# print(data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCYN51OyRLUt",
        "outputId": "f273b048-95c9-487a-b951-9dba3f016c7d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocessing\n",
        "columns_to_drop = [\n",
        "    \"name\", \"email\", \"phone-number\", \"credit_card\", \"reservation_status_date\",\n",
        "    \"reservation_status\", \"company\", \"agent\"\n",
        "]\n",
        "\n",
        "processed_data = data.drop(columns=columns_to_drop)\n",
        "\n",
        "processed_data[\"children\"].fillna(0, inplace=True)\n",
        "processed_data[\"country\"].fillna(\"Unknown\", inplace=True)\n",
        "\n",
        "categorical_columns = [\n",
        "    \"hotel\", \"arrival_date_month\", \"meal\", \"country\", \"market_segment\",\n",
        "    \"distribution_channel\", \"reserved_room_type\", \"assigned_room_type\",\n",
        "    \"deposit_type\", \"customer_type\"\n",
        "]\n",
        "\n",
        "numerical_columns = [\n",
        "    \"lead_time\", \"arrival_date_week_number\", \"arrival_date_day_of_month\",\n",
        "    \"stays_in_weekend_nights\", \"stays_in_week_nights\", \"adults\", \"children\",\n",
        "    \"babies\", \"previous_cancellations\", \"previous_bookings_not_canceled\",\n",
        "    \"booking_changes\", \"days_in_waiting_list\", \"adr\",\n",
        "    \"required_car_parking_spaces\", \"total_of_special_requests\"\n",
        "]\n",
        "\n",
        "X = processed_data.drop(columns=[\"is_canceled\"])\n",
        "y = processed_data[\"is_canceled\"]\n",
        "\n",
        "# for logistic regression\n",
        "preprocessorLog = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", StandardScaler(), numerical_columns),\n",
        "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_columns)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# for decision trees and random forests, no scale\n",
        "preprocessorDT = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", Pipeline([\n",
        "            ('imputer', SimpleImputer(strategy='mean')),\n",
        "            ('passthrough', 'passthrough')\n",
        "        ]), numerical_columns),\n",
        "        (\"cat\", Pipeline([\n",
        "            ('imputer', SimpleImputer(strategy='constant', fill_value='Unknown')),\n",
        "            ('onehot', OneHotEncoder(handle_unknown=\"ignore\"))\n",
        "        ]), categorical_columns)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# for neural networks, don't know if it will work or not\n",
        "preprocessor_nn = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", StandardScaler(), numerical_columns),\n",
        "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_columns)\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "pipeline_Log = Pipeline(steps=[(\"preprocessor\", preprocessorLog)])\n",
        "X_train_Log = pipeline_Log.fit_transform(X_train)\n",
        "X_test_Log = pipeline_Log.transform(X_test)\n",
        "\n",
        "pipeline_DT = Pipeline(steps=[(\"preprocessor\", preprocessorDT)])\n",
        "X_train_DT = pipeline_DT.fit_transform(X_train)\n",
        "X_test_DT = pipeline_DT.transform(X_test)\n",
        "\n",
        "pipeline_nn = Pipeline(steps=[(\"preprocessor\", preprocessor_nn)])\n",
        "X_train_nn = pipeline_nn.fit_transform(X_train)\n",
        "X_test_nn = pipeline_nn.transform(X_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "PeAcAXmVZXiY",
        "outputId": "a40c8a49-c9ca-4949-cb56-e268709648ef"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-928b56ecc4fa>:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  processed_data[\"children\"].fillna(0, inplace=True)\n",
            "<ipython-input-3-928b56ecc4fa>:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  processed_data[\"country\"].fillna(\"Unknown\", inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression\n",
        "class MyLogisticRegression:\n",
        "    def __init__(self):\n",
        "        self.model_logistic = None\n",
        "\n",
        "    def model_fit_logistic(self):\n",
        "        self.model_logistic = LogisticRegression(max_iter=500)\n",
        "\n",
        "        self.model_logistic.fit(X_train_Log, y_train)\n",
        "\n",
        "    def model_predict_logistic(self):\n",
        "        self.model_fit_logistic()\n",
        "\n",
        "        accuracy = 0.0\n",
        "        precision, recall, f1, support = np.array([0,0]), np.array([0,0]), np.array([0,0]), np.array([0,0])\n",
        "\n",
        "        if X_test_Log is not None:\n",
        "            y_pred = self.model_logistic.predict(X_test_Log)\n",
        "            accuracy = accuracy_score(y_test, y_pred)\n",
        "            precision, recall, f1, support = precision_recall_fscore_support(y_test, y_pred, average=None)\n",
        "\n",
        "        assert precision.shape == recall.shape == f1.shape == support.shape == (2,), \"precision, recall, f1, support should be an array of shape (2,)\"\n",
        "\n",
        "        return accuracy, precision, recall, f1, support"
      ],
      "metadata": {
        "id": "Py5YkWCEgtr9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logModel = MyLogisticRegression()\n",
        "\n",
        "accuracyLog, precisionLog, recallLog, f1Log, supportLog = logModel.model_predict_logistic()\n",
        "print(accuracyLog, precisionLog, recallLog, f1Log, supportLog)\n",
        "print('Accuracy: {}'.format(accuracyLog))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "401v6lR9YKxP",
        "outputId": "fb0f1d49-99fe-4194-9357-8139b648b429"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8202948320629868 [0.81910545 0.82302595] [0.91400013 0.66458589] [0.86395485 0.73536849] [14907  8971]\n",
            "Accuracy: 0.8202948320629868\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For Logistic Regression: recall for is_cancelled = 1 is low (66%), f1 support is low (73%), everything else is above 80%."
      ],
      "metadata": {
        "id": "rsYKX_f08JcF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest Classifier\n",
        "class MyRandomForest:\n",
        "  def __init__(self):\n",
        "        self.model_rf = None\n",
        "  def model_fit_rf(self):\n",
        "    self.model_rf = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=30, min_samples_split=2)\n",
        "\n",
        "    self.model_rf.fit(X_train_DT, y_train)\n",
        "\n",
        "  def model_predict_rf(self):\n",
        "        # self.model_fit_rf()\n",
        "\n",
        "        accuracy = 0.0\n",
        "        precision, recall, f1, support = np.array([0,0]), np.array([0,0]), np.array([0,0]), np.array([0,0])\n",
        "\n",
        "        if X_test_DT is not None:\n",
        "            y_pred = self.model_rf.predict(X_test_DT)\n",
        "            accuracy = accuracy_score(y_test, y_pred)\n",
        "            precision, recall, f1, support = precision_recall_fscore_support(y_test, y_pred, average=None)\n",
        "\n",
        "        assert precision.shape == recall.shape == f1.shape == support.shape == (2,), \"precision, recall, f1, support should be an array of shape (2,)\"\n",
        "\n",
        "        return accuracy, precision, recall, f1, support\n",
        "\n",
        "  def predict_single_rf(self, X_test, index):\n",
        "    if self.model_rf is None:\n",
        "      raise ValueError(\"The model has not been trained. Call model_fit_rf first.\")\n",
        "\n",
        "    if index < 0 or index >= X_test.shape[0]:\n",
        "      raise IndexError(f\"Index out of bounds. Please select an index between 0 and {X_test.shape[0] - 1}.\")\n",
        "\n",
        "    single_sample = X_test[index].reshape(1, -1)  # Reshape for a single prediction\n",
        "    prediction = self.model_rf.predict(single_sample)\n",
        "    return prediction[0]"
      ],
      "metadata": {
        "id": "gEYG1pCFgwAh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rfModel = MyRandomForest()\n",
        "rfModel.model_fit_rf()\n",
        "accuracyRF, precisionRF, recallRF, f1RF, supportRF = rfModel.model_predict_rf()\n",
        "print(accuracyRF, precisionRF, recallRF, f1RF, supportRF)\n",
        "print('Accuracy: {}'.format(accuracyRF))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gW12metD_nYh",
        "outputId": "dabbd970-dc6c-4310-8256-f6f3283ca1d7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8847474662869587 [0.87920384 0.8960642 ] [0.94526062 0.78419351] [0.9110364  0.83640471] [14907  8971]\n",
            "Accuracy: 0.8847474662869587\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# XGBoost\n",
        "class MyXGBoost:\n",
        "  def __init__(self):\n",
        "        self.model_xg = None\n",
        "  def model_fit_xg(self):\n",
        "    self.model_xg = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
        "\n",
        "    self.model_xg.fit(X_train_DT, y_train)\n",
        "\n",
        "  def model_predict_xg(self):\n",
        "        # self.model_fit_xg()\n",
        "\n",
        "        accuracy = 0.0\n",
        "        precision, recall, f1, support = np.array([0,0]), np.array([0,0]), np.array([0,0]), np.array([0,0])\n",
        "\n",
        "        if X_test_DT is not None:\n",
        "            y_pred = self.model_xg.predict(X_test_DT)\n",
        "            accuracy = accuracy_score(y_test, y_pred)\n",
        "            precision, recall, f1, support = precision_recall_fscore_support(y_test, y_pred, average=None)\n",
        "\n",
        "        assert precision.shape == recall.shape == f1.shape == support.shape == (2,), \"precision, recall, f1, support should be an array of shape (2,)\"\n",
        "\n",
        "        return accuracy, precision, recall, f1, support"
      ],
      "metadata": {
        "id": "ieAqEHe2BBfH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgModel = MyXGBoost()\n",
        "xgModel.model_fit_xg()\n",
        "accuracyXG, precisionXG, recallXG, f1XG, supportXG = xgModel.model_predict_xg()\n",
        "print(accuracyXG, precisionXG, recallXG, f1XG, supportXG)\n",
        "print('Accuracy: {}'.format(accuracyXG))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eVAq5iGBlo-",
        "outputId": "b622b950-3d04-4f7d-d580-f6eeb12c5082"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [20:13:03] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8721417204120948 [0.88101054 0.85556357] [0.91936674 0.79366849] [0.89978006 0.82345458] [14907  8971]\n",
            "Accuracy: 0.8721417204120948\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For Random Forest: better than logistic regression, 78% is the lowest (cancelled=1 recall)"
      ],
      "metadata": {
        "id": "OasOYMnKCICC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Decision Tree Classifier\n",
        "class MyDecisionTree:\n",
        "    def __init__(self):\n",
        "        self.model_dt = None\n",
        "\n",
        "    def model_fit_dt(self):\n",
        "        # Initialize\n",
        "        self.model_dt = DecisionTreeClassifier(random_state=42, max_depth=30, min_samples_split=2)\n",
        "        # Fit the model\n",
        "        self.model_dt.fit(X_train_DT, y_train)\n",
        "\n",
        "    def model_predict_dt(self):\n",
        "        # Train the model\n",
        "        self.model_fit_dt()\n",
        "\n",
        "        accuracy = 0.0\n",
        "        precision, recall, f1, support = np.array([0, 0]), np.array([0, 0]), np.array([0, 0]), np.array([0, 0])\n",
        "\n",
        "        if X_test_DT is not None:\n",
        "            # Predict on the test set\n",
        "            y_pred = self.model_dt.predict(X_test_DT)\n",
        "            # Evaluate the model\n",
        "            accuracy = accuracy_score(y_test, y_pred)\n",
        "            precision, recall, f1, support = precision_recall_fscore_support(y_test, y_pred, average=None)\n",
        "\n",
        "        assert precision.shape == recall.shape == f1.shape == support.shape == (2,), \"precision, recall, f1, support should be an array of shape (2,)\"\n",
        "\n",
        "        return accuracy, precision, recall, f1, support\n"
      ],
      "metadata": {
        "id": "uoNBTv9ahhIs"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dtModel = MyDecisionTree()\n",
        "\n",
        "# Train and evaluate the Decision Tree model\n",
        "accuracyDT, precisionDT, recallDT, f1DT, supportDT = dtModel.model_predict_dt()\n",
        "\n",
        "# Print results\n",
        "print(accuracyDT, precisionDT, recallDT, f1DT, supportDT)\n",
        "print('Accuracy: {}'.format(accuracyDT))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhg1BKqjrLq1",
        "outputId": "761c1fc0-8b7e-49db-f926-fd216c7e9712"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.855054862216266 [0.88383635 0.80720339] [0.88401422 0.80693345] [0.88392528 0.8070684 ] [14907  8971]\n",
            "Accuracy: 0.855054862216266\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Neural Network Classifier\n",
        "class MyNeuralNetwork:\n",
        "    def __init__(self):\n",
        "        self.model_nn = None\n",
        "\n",
        "    def model_fit_nn(self):\n",
        "        # Initialize\n",
        "        self.model_nn = MLPClassifier(\n",
        "            hidden_layer_sizes=(100,),\n",
        "            #hidden_layer_sizes=(128, 64),  # Two hidden layers\n",
        "            activation='relu',\n",
        "            solver='adam',\n",
        "            max_iter=50,#change\n",
        "            random_state=42\n",
        "        )\n",
        "        # Fit\n",
        "        self.model_nn.fit(X_train_nn, y_train)\n",
        "\n",
        "    def model_predict_nn(self):\n",
        "        # Train\n",
        "        self.model_fit_nn()\n",
        "\n",
        "        accuracy = 0.0\n",
        "        precision, recall, f1, support = np.array([0, 0]), np.array([0, 0]), np.array([0, 0]), np.array([0, 0])\n",
        "\n",
        "        if X_test_nn is not None:\n",
        "            # Predict\n",
        "            y_pred = self.model_nn.predict(X_test_nn)\n",
        "            # Evaluate\n",
        "            accuracy = accuracy_score(y_test, y_pred)\n",
        "            precision, recall, f1, support = precision_recall_fscore_support(y_test, y_pred, average=None)\n",
        "\n",
        "        assert precision.shape == recall.shape == f1.shape == support.shape == (2,), \"precision, recall, f1, support should be an array of shape (2,)\"\n",
        "\n",
        "        return accuracy, precision, recall, f1, support\n"
      ],
      "metadata": {
        "id": "MuYJmBh4hlyH"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nnModel = MyNeuralNetwork()\n",
        "\n",
        "# Train and evaluate\n",
        "accuracyNN, precisionNN, recallNN, f1NN, supportNN = nnModel.model_predict_nn()\n",
        "\n",
        "print(accuracyNN, precisionNN, recallNN, f1NN, supportNN)\n",
        "print('Accuracy: {}'.format(accuracyNN))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "673uzs394-1y",
        "outputId": "9d55e1ba-24c1-4a2e-b87a-d6a1505baf1f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8671161738839098 [0.87081279 0.85985601] [0.92426377 0.77215472] [0.89674249 0.81364891] [14907  8971]\n",
            "Accuracy: 0.8671161738839098\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # Initialize and train the model\n",
        "    # rfModel = MyRandomForest()\n",
        "    # rfModel.model_fit_rf(X_train_DT, y_train)\n",
        "\n",
        "    # Ask the user for input\n",
        "    try:\n",
        "        index = int(input(f\"Enter the index of the test data to predict (0 to {X_test_DT.shape[0] - 1}): \"))\n",
        "        prediction = rfModel.predict_single_rf(X_test_DT, index)\n",
        "        actual = y_test.iloc[index]  # Assuming y_test is a Pandas Series or similar structure\n",
        "\n",
        "        # Convert prediction and actual values to descriptive labels\n",
        "        predLabel = \"booking cancelled\" if prediction == 1 else \"booking kept\"\n",
        "        actualLabel = \"booking cancelled\" if actual == 1 else \"booking kept\"\n",
        "\n",
        "        print(f\"Prediction for test data at index {index}: {predLabel}\")\n",
        "        print(f\"Actual value: {actualLabel}\")\n",
        "\n",
        "        if prediction == actual:\n",
        "            print(\"The prediction is spot on! AI will soon take over the world!\")\n",
        "        else:\n",
        "            print(\"The prediction is incorrect.\")\n",
        "    except ValueError:\n",
        "        print(\"Please enter a usable integer.\")\n",
        "    except Exception as e:\n",
        "        print(str(e))\n",
        "\n",
        "# Run the main function\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQCbldjxEWM7",
        "outputId": "155008da-57dc-4949-85da-da4f3e425f0f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the index of the test data to predict (0 to 23877): 2\n",
            "Prediction for test data at index 2: booking kept\n",
            "Actual value: booking kept\n",
            "The prediction is spot on! AI will soon take over the world!\n"
          ]
        }
      ]
    }
  ]
}